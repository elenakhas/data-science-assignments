{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise sheet \\#3\n",
    "\n",
    "Here, you will have to implement a web scraping engine, which will retrieve data from the famous [Internet Movie DataBase](https://www.imdb.com/) (IMDB).\n",
    "The data we are interested in is **movie ratings**. \n",
    "\n",
    "Before starting, we need to keep in mind that requesting webpage could be time consuming. Should we want to build a large dataset, we would need to pay attention to the number of requests sent by our scraping engine (and to their frequency to avoid being black listed by IMDB's servers).\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Let us inspect the following IMDB entry : [Movie tt0211915](https://www.imdb.com/title/tt0211915/).\n",
    "\n",
    "On this page, you can find at least two ratings: the one by IMDB and the one by mediacritic. By pressing Ctrl+U, you can access the page's source code, and on chrome by clicking F12 you can launch the DevTools panel.\n",
    "\n",
    "Where are located these ratings in the underlying HTML code ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_To be completed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Write a python program which retrieves the page located at the URL given above, parses it and extract the ratings of that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "69\n",
      " \n",
      "8.3/10 \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "page=requests.get('https://www.imdb.com/title/tt0211915/')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "metacritic = soup.find_all(class_='metacriticScore score_favorable titleReviewBarSubItem')[0]\n",
    "score = metacritic.get_text()\n",
    "\n",
    "reviewer = soup.find_all(class_='ratingValue')[0]\n",
    "score2 = reviewer.get_text()\n",
    "print(score, score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "By using IMDB's advanced search feature, can you list the movies released in 2018 by decreasing number of ratings (not descreasing ratings!) ? Describes the actions you performed on IMDB's web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_To be completed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URL of the first page of the search results looks like the following (250 results per page to save time during future retrieval):\n",
    "\n",
    "`https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&count=250`\n",
    "\n",
    "Note also the URL of the second page of the search results:\n",
    "\n",
    "`https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&count=250&start=251&ref_=adv_nxt`\n",
    "\n",
    "### Question 4\n",
    "\n",
    "Write a python program which retrieves the ten first pages of results and store them locally (that is, save a local copy of each of them). Apply a 3-second sleep between requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cb57a0f46b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mQuotesSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MovieSpider'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&count=250'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'MovieSpider'\n",
    "    start_urls = ['https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&count=250']\n",
    "       \n",
    "    def parse(self, response):\n",
    "        page = response.url.split('/')\n",
    "        filename = 'movie_search-%s.html' %page\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        next_page = response.css('a.lister-page-next\\ next-page::attr(\"href\")').extract_first()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, callback=self.parse)\n",
    "\n",
    "\n",
    "if name=='main':\n",
    "    import scrapy.crawler\n",
    "    myspider = QuotesSpider()\n",
    "    process = scrapy.crawler.CrawlerProcess({'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'})\n",
    "    process.crawl(myspider)\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Describes the path where the movie information appears in the HTML tree of the retrieved webpages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_To be completed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Extend the python program from Question 4 so that the following information is extracted for each movie:\n",
    "\n",
    "- name of the movie\n",
    "- year of release\n",
    "- number of votes\n",
    "- IMDB rating\n",
    "- Metacritic score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse(self, response):\n",
    "        with open('movies.txt', ‘a’) as f:\n",
    "            movie = response.html(“div.quote”)\n",
    "            for quote in quotes:\n",
    "               text = quote.css(‘span.text::text’).extract_first()\n",
    "               print(text,file=f)\n",
    "            next_page = response.css(‘li.next a::attr(href)’).extract_first()\n",
    "    if next_page is not None:\n",
    "        yield response.follow(next_page, callback=self.parse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Extend the python program from Question 6 so that the results of extraction are stored in a [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Manually inspect the results of your data extraction. Are there any errors (missing information, ill-formed data, etc.) ? If so, extend your python script to fix these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "On-line [tutorial](https://www.dataquest.io/blog/web-scraping-beautifulsoup/) entitled \"Web Scraping with Python and BeautifulSoup\" by Alex Olteanu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
